ğƒğ€ğ˜ ğŸ ğğ… ğ“ğ‡ğ„ ğŸğŸ ğƒğ€ğ˜ğ’ ğğ… ğğ˜ğ’ğğ€ğ‘ğŠ ğ‚ğ‡ğ€ğ‹ğ‹ğ„ğğ†ğ„ started with the basics.

-- ğŸ. ğğ®ğğ¬ğ­ğ¢ğ¨ğ§: ğ‹ğ¢ğ¬ğ­ ğšğ¥ğ¥ ğ®ğ§ğ¢ğªğ®ğ ğ¡ğ¨ğ¬ğ©ğ¢ğ­ğšğ¥ ğ¬ğğ«ğ¯ğ¢ğœğğ¬ ğšğ¯ğšğ¢ğ¥ğšğ›ğ¥ğ ğ¢ğ§ ğ­ğ¡ğ ğ¡ğ¨ğ¬ğ©ğ¢ğ­ğšğ¥.


-- ğˆğ§ğ¢ğ­ğ¢ğšğ­ğ ğ’ğ©ğšğ«ğ¤ ğ’ğğ¬ğ¬ğ¢ğ¨ğ§.

ğŸğ«ğ¨ğ¦ ğ©ğ²ğ¬ğ©ğšğ«ğ¤.ğ¬ğªğ¥ import ğ’ğ©ğšğ«ğ¤ğ’ğğ¬ğ¬ğ¢ğ¨ğ§

-- ğ‚ğ«ğğšğ­ğ ğ¨ğ« ğ†ğğ­ ğšğ§ ğ„ğ±ğ¢ğ¬ğ­ğ¢ğ§ğ  ğ’ğ©ğšğ«ğ¤ ğ’ğğ¬ğ¬ğ¢ğ¨ğ§.

ğ¬ğ©ğšğ«ğ¤ = ğ’ğ©ğšğ«ğ¤ğ’ğğ¬ğ¬ğ¢ğ¨ğ§.ğ›ğ®ğ¢ğ¥ğğğ«.ğšğ©ğ©ğğšğ¦ğ("Hospital").ğ ğğ­ğğ«ğ‚ğ«ğğšğ­ğ()

-- ğ‹ğ¨ğšğ ğ²ğ¨ğ®ğ« ğğšğ­ğš (ğ’ğğ«ğ¯ğ¢ğœğğ¬_ğ–ğğğ¤ğ¥ğ² ğ¢ğ¬ ğš ğ‚ğ’ğ• ğŸğ¢ğ¥ğ; ğ®ğ©ğğšğ­ğ ğ©ğšğ­ğ¡/ğŸğ¨ğ«ğ¦ğšğ­ ğšğ¬ ğ§ğğğğğ).

ğ’ğğ«ğ¯ğ¢ğœğğ¬_ğ–ğğğ¤ğ¥ğ² = ğ¬ğ©ğšğ«ğ¤.ğ«ğğšğ.ğŸğ¨ğ«ğ¦ğšğ­("ğœğ¬ğ¯").ğ¨ğ©ğ­ğ¢ğ¨ğ§("ğ‡ğğšğğğ«", ğ“ğ«ğ®ğ).ğ¥ğ¨ğšğ("/21DaysPySparkChallenge/Datasets/services_weekly.csv").

-- ğ’ğ‡ğğ– ğ’ğğ«ğ¯ğ¢ğœğğ¬_ğ–ğğğ¤ğ¥ğ².ğœğ¬ğ¯ ğ…ğ¢ğ¥ğ ğƒğšğ­ğšğŸğ«ğšğ¦ğ.

ğ’ğğ«ğ¯ğ¢ğœğğ¬_ğ–ğğğ¤ğ¥ğ².ğ¬ğ¡ğ¨ğ°()

-- ğƒğšğ² - ğŸ - ğ“ğšğ¬ğ¤: ğ‹ğ¢ğ¬ğ­ ğšğ¥ğ¥ ğ®ğ§ğ¢ğªğ®ğ ğ¡ğ¨ğ¬ğ©ğ¢ğ­ğšğ¥ ğ¬ğğ«ğ¯ğ¢ğœğğ¬ ğšğ¯ğšğ¢ğ¥ğšğ›ğ¥ğ ğ¢ğ§ ğ­ğ¡ğ ğ¡ğ¨ğ¬ğ©ğ¢ğ­ğšğ¥. ğ†ğğ­ ğğ§ğ¥ğ² ğ”ğğˆğğ”ğ„ ğ’ğğ«ğ¯ğ¢ğœğğ¬ (ğ„ğªğ®ğ¢ğ¯ğšğ¥ğğ§ğ­ ğ“ğ¨ ğƒğˆğ’ğ“ğˆğğ‚ğ“).

ğ”ğ§ğ¢ğªğ®ğ_ğ’ğğ«ğ¯ğ¢ğœğğ¬ = ğ’ğğ«ğ¯ğ¢ğœğğ¬_ğ–ğğğ¤ğ¥ğ².ğ¬ğğ¥ğğœğ­("service").ğğ¢ğ¬ğ­ğ¢ğ§ğœğ­()

-- ğ’ğ‡ğğ– ğš ğƒğšğ­ğšğ…ğ«ğšğ¦ğ (ğ€ğ‚ğ“ğˆğğ).

ğ”ğ§ğ¢ğªğ®ğ_ğ’ğğ«ğ¯ğ¢ğœğğ¬.ğ¬ğ¡ğ¨ğ°()

-- ğŒğ˜ ğ‹ğ„ğ€ğ‘ğğˆğğ†.

ğ’ğ­ğšğ«ğ­ ğ°ğ¢ğ­ğ¡ ğš ğ’ğ©ğšğ«ğ¤ğ’ğğ¬ğ¬ğ¢ğ¨ğ§: Every PySpark job begins with creating or using an existing SparkSession. This is the entry point for any DataFrame operations in Spark.

ğƒğšğ­ğš ğ‹ğ¨ğšğğ¢ğ§ğ  ğ°ğ¢ğ­ğ¡ ğƒğšğ­ğšğ…ğ«ğšğ¦ğ ğ€ğğˆ: PySpark makes it easy to load data from various sources (CSV, Parquet, databases, etc.) using spark.read. You can specify options like header=True for CSVs to correctly interpret your columns.

ğƒğšğ­ğš ğ„ğ±ğ©ğ¥ğ¨ğ«ğšğ­ğ¢ğ¨ğ§: Using .show(), you can preview your data to verify that itâ€™s loaded correctly and check the structure â€” this is a good habit for every new dataset.

ğ“ğ«ğšğ§ğ¬ğŸğ¨ğ«ğ¦ğšğ­ğ¢ğ¨ğ§ğ¬ ğŸğ¨ğ« ğƒğ¢ğ¬ğ­ğ¢ğ§ğœğ­ ğ•ğšğ¥ğ®ğğ¬: The method .select("Service").distinct() achieves the same result as SQLâ€™s SELECT DISTINCT. Itâ€™s efficient and directly returns only the unique service values present in the DataFrame.
